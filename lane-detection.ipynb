{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road Lane Detection with U-Net Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            # Allow memory growth\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth enabled for GPUs.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"tusimple_preprocessed/training\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a generator and get the images from the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_generator = keras.preprocessing.image.ImageDataGenerator()\n",
    "seed = 10\n",
    "images_set = img_generator.flow_from_directory(\n",
    "    train_path,\n",
    "    shuffle=False,\n",
    "    batch_size=64,\n",
    "    class_mode=\"binary\",\n",
    "    target_size=(256, 320),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assign the images in 'images_set' to two seperate arrays:\n",
    "assign the road images to 'X' and the ground truth masks to 'Y'\n",
    "\"\"\"\n",
    "num_images = 7252  # gotten from the output of the cell above\n",
    "num_batches = num_images // 64 + 1\n",
    "\n",
    "# initialize an empty list to store the images\n",
    "X = []\n",
    "Y = []\n",
    "# loop over the batches and extract the images\n",
    "for i in range(num_batches):\n",
    "    batch = next(images_set)\n",
    "    batch_images = batch[0]  # this contains the images\n",
    "    batch_labels = batch[1]  # this contains 0s and 1s\n",
    "    for ind, lb in enumerate(batch_labels):\n",
    "        \"\"\"\n",
    "        a label of 0 means the image belongs to ground truth image,\n",
    "        and a label of 1 means that the image belongs to the ground truth mask\n",
    "        \"\"\"\n",
    "        if lb == 0:\n",
    "            X.append(batch_images[ind])\n",
    "        else:\n",
    "            Y.append(np.mean(batch_images[ind], axis=2))  # Y shape is (m, 256, 320)\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Batch {i}\")\n",
    "\n",
    "# convert the lists to numpy arrays\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X.shape)\n",
    "display(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X, Y = shuffle(X, Y, random_state=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# becacuse of lack of resources like RAM, we only get 2000 training samples\n",
    "X = np.array(X[:2000])\n",
    "Y = np.array(Y[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X.shape)\n",
    "display(Y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and reshape the mask set (Y)\n",
    "Y = (Y >= 100).astype(\"int\").reshape(-1, 256, 320, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.min(), Y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we get 2000 images for training and evaluation\n",
    "X = np.array(X[:2000])\n",
    "Y = np.array(Y[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Dataset into Train and Val sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.1, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_val:\", X_val.shape)\n",
    "print(\"Shape of Y_train:\", Y_train.shape)\n",
    "print(\"Shape of Y_val:\", Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free the RAM from undesired clutters\n",
    "import gc\n",
    "\n",
    "del X, Y, images_set\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some samples from the training set\n",
    "plt.figure(figsize=(10, 40))\n",
    "s, e = 80, 84\n",
    "index = 1\n",
    "\n",
    "for i, j in zip(X_train[s:e], Y_train[s:e]):\n",
    "    plt.subplot(10, 2, index)\n",
    "    plt.imshow(i / 255.0)\n",
    "    plt.title(\"Ground truth image\")\n",
    "\n",
    "    plt.subplot(10, 2, index + 1)\n",
    "    plt.imshow(j, cmap=\"gray\")\n",
    "    plt.title(\"Ground truth mask\")\n",
    "    index += 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model structure\n",
    "from tensorflow.keras.layers import Input, Conv2DTranspose, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "# Define the input shape of the images\n",
    "input_shape = (256, 320, 3)\n",
    "\n",
    "# Define the encoder using a pretrained ResNet50 model\n",
    "encoder = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "'''\n",
    "Find the index of the layer named conv3_block4_out of which output size is (32x32xnC)\n",
    " because we want to shrink the input's size down upto (32x32xnC) in the encoder section\n",
    "'''\n",
    "\n",
    "for i, layer in enumerate(encoder.layers):\n",
    "    if layer.name == 'conv3_block4_out':\n",
    "        break\n",
    "\n",
    "# Create a new model that includes only the layers up to conv3_block4_out\n",
    "encoder = tf.keras.Model(inputs=encoder.inputs, outputs=encoder.layers[i].output)\n",
    "\n",
    "# Freeze the weights of the encoder layers to prevent them from being updated during training\n",
    "for layer in encoder.layers[:50]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define the decoder using a smaller FCN architecture\n",
    "def decoder(inputs):\n",
    "    conv1 = Conv2D(256, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    up1 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(up1)\n",
    "    up2 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(64, (3, 3), activation='relu', padding='same')(up2)\n",
    "    up3 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv3)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(up3)\n",
    "    return outputs\n",
    "\n",
    "# Define the input tensor\n",
    "inputs = Input(input_shape)\n",
    "\n",
    "# Pass the input through the encoder and decoder to obtain the output\n",
    "outputs = decoder(encoder(inputs))\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=keras.losses.BinaryFocalCrossentropy(), metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "\n",
    "class MetricsLogger(Callback):\n",
    "    def __init__(self, X_val, Y_val):\n",
    "        super().__init__()\n",
    "        self.X_val = X_val\n",
    "        self.Y_val = Y_val\n",
    "        self.epoch_metrics = {\n",
    "            \"accuracy\": [],\n",
    "            \"precision\": [],\n",
    "            \"recall\": [],\n",
    "            \"f1_score\": [],\n",
    "            \"iou\": [],\n",
    "        }\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        preds = (self.model.predict(self.X_val) >= 0.5).astype(\"int\")\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = tf.keras.metrics.Accuracy()\n",
    "        precision = tf.keras.metrics.Precision()\n",
    "        recall = tf.keras.metrics.Recall()\n",
    "        iou = tf.keras.metrics.IoU(num_classes=2, target_class_ids=[1])\n",
    "\n",
    "        accuracy.update_state(self.Y_val, preds)\n",
    "        precision.update_state(self.Y_val, preds)\n",
    "        recall.update_state(self.Y_val, preds)\n",
    "        iou.update_state(self.Y_val, preds)\n",
    "\n",
    "        accuracy_value = accuracy.result().numpy()\n",
    "        precision_value = precision.result().numpy()\n",
    "        recall_value = recall.result().numpy()\n",
    "        f1_score_value = 2 / ((1 / precision_value) + (1 / recall_value))\n",
    "        iou_value = iou.result().numpy()\n",
    "\n",
    "        # Store metrics\n",
    "        self.epoch_metrics[\"accuracy\"].append(accuracy_value)\n",
    "        self.epoch_metrics[\"precision\"].append(precision_value)\n",
    "        self.epoch_metrics[\"recall\"].append(recall_value)\n",
    "        self.epoch_metrics[\"f1_score\"].append(f1_score_value)\n",
    "        self.epoch_metrics[\"iou\"].append(iou_value)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1} - Accuracy: {accuracy_value:.4f}, Precision: {precision_value:.4f}, Recall: {recall_value:.4f}, \"\n",
    "            f\"F1 Score: {f1_score_value:.4f}, IoU: {iou_value:.4f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Instantiate the custom metrics logger\n",
    "metrics_logger = MetricsLogger(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "epochs = 32\n",
    "batch_size = 8\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\"), metrics_logger]\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_val)\n",
    "preds.max(), preds.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a directory to store some predicted lane masks\n",
    "!mkdir out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some results from the val set.\n",
    "plt.figure(figsize=(10, 45))\n",
    "s, e = 90, 98\n",
    "index = 1\n",
    "\n",
    "preds = (preds >= 0.5).astype(\"int\")\n",
    "for i, j, k in zip(X_val[s:e], preds[s:e], Y_val[s:e]):\n",
    "    # write these images into file as well\n",
    "    cv2.imwrite(f\"./out/img-{index}.jpg\", i)\n",
    "    cv2.imwrite(f\"./out/pred-{index}.jpg\", j * 255.0)\n",
    "    cv2.imwrite(f\"./out/ground-{index}.jpg\", k * 255.0)\n",
    "\n",
    "    plt.subplot(10, 2, index)\n",
    "    plt.imshow(i / 255.0)\n",
    "    plt.title(\"Ground truth image\")\n",
    "\n",
    "    plt.subplot(10, 2, index + 1)\n",
    "    plt.imshow(j, cmap=\"gray\")\n",
    "    plt.title(\"Pred mask\")\n",
    "    index += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip out.zip out -r -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save(\"/lane-detection-model-fcn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create metrices\n",
    "accuracy = tf.keras.metrics.Accuracy()\n",
    "precision = tf.keras.metrics.Precision()\n",
    "recal = tf.keras.metrics.Recall()\n",
    "iou = tf.keras.metrics.IoU(num_classes=2, target_class_ids=[1])\n",
    "\n",
    "\n",
    "# accuracy\n",
    "accuracy.update_state(Y_val, preds)\n",
    "accuracy_value = accuracy.result().numpy()\n",
    "# precision\n",
    "precision.update_state(Y_val, preds)\n",
    "precision_value = precision.result().numpy()\n",
    "# recal\n",
    "recal.update_state(Y_val, preds)\n",
    "recal_value = recal.result().numpy()\n",
    "# f1 score\n",
    "f1_score = 2 / ((1 / precision_value) + (1 / recal_value))\n",
    "\n",
    "# Intersection over union (IoU)\n",
    "iou.update_state(Y_val, preds)\n",
    "iou_value = iou.result().numpy()\n",
    "\n",
    "print(\"Accuracy:\", accuracy_value)\n",
    "print(\"Precision:\", precision_value)\n",
    "print(\"Recal:\", recal_value)\n",
    "print(\"F1 Score: \", f1_score)\n",
    "print(\"IoU: \", iou_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metrics\n",
    "epoch_list = range(1, len(metrics_logger.epoch_metrics[\"accuracy\"]) + 1)\n",
    "accuracy = metrics_logger.epoch_metrics[\"accuracy\"]\n",
    "precision = metrics_logger.epoch_metrics[\"precision\"]\n",
    "recall = metrics_logger.epoch_metrics[\"recall\"]\n",
    "f1_score = metrics_logger.epoch_metrics[\"f1_score\"]\n",
    "iou = metrics_logger.epoch_metrics[\"iou\"]\n",
    "\n",
    "# Plot Accuracy Progress\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epoch_list, accuracy, label=\"Accuracy\", color=\"blue\", linewidth=2)\n",
    "plt.title(\"Accuracy Progress Over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot Precision Progress\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epoch_list, precision, label=\"Precision\", color=\"green\", linewidth=2)\n",
    "plt.title(\"Precision Progress Over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot Recall Progress\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epoch_list, recall, label=\"Recall\", color=\"orange\", linewidth=2)\n",
    "plt.title(\"Recall Progress Over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot F1 Score Progress\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epoch_list, f1_score, label=\"F1 Score\", color=\"red\", linewidth=2)\n",
    "plt.title(\"F1 Score Progress Over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot IoU Progress\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epoch_list, iou, label=\"IoU\", color=\"purple\", linewidth=2)\n",
    "plt.title(\"IoU Progress Over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
